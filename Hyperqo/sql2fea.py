import sys

sys.path.append(".")

from JOBParser import TargetTable, FromTable, Comparison
# max_column_in_table = 15
import torch
import torch
import torch.nn as nn
from itertools import count
import numpy as np
from PGUtils import pgrunner
from JOBParser import TargetTable, FromTable, Comparison
from ImportantConfig import Config
import os

config = Config()


def zero_hc(input_dim=1):
    return torch.zeros(input_dim, config.hidden_size, device=config.device), torch.zeros(input_dim, config.hidden_size,
                                                                                         device=config.device)


column_id = {}


def getColumnId(column):
    if not column in column_id:
        column_id[column] = len(column_id)
    return column_id[column]


def _nn_path(base):
    return os.path.join(base, "nn_weights")


def _feature_generator_path(base):
    return os.path.join(base, "feature_generator")


def _input_feature_dim_path(base):
    return os.path.join(base, "input_feature_dim")


class Sql2Vec:
    def __init__(self, ):
        pass

    def to_vec(self, sql):
        from psqlparse import parse_dict
        self.sql = sql
        import time
        # startTime = time.time()
        """
        parse_result = {'targetList': [{...}, {...}], 'fromClause': [{...}, {...}, {...}, {...}, {...}, {...}, {...}, {...}], 
        'whereClause': {'BoolExpr': {...}}, 'op': 0}
        """
        parse_result = parse_dict(self.sql)[0]["SelectStmt"]
        self.target_table_list = [TargetTable(x["ResTarget"]) for x in parse_result["targetList"]]
        # [<JOBParser.TargetTable object at 0x7f70ed1ff410>, <JOBParser.TargetTable object at 0x7f70ed1fac50>]
        self.from_table_list = [FromTable(x["RangeVar"]) for x in parse_result["fromClause"]]
        if len(self.from_table_list) < 2:
            return
        self.aliasname2fullname = {}

        self.id2aliasname = config.id2aliasname
        self.aliasname2id = config.aliasname2id
        # self.id2aliasname = {0: 'start', 1: 'chn', 2: 'ci', 3: 'cn', 4: 'ct', 5: 'mc', 6: 'rt', 7: 't', 8: 'k', 9: 'lt', 10: 'mk', 11: 'ml', 12: 'it1', 13: 'it2', 14: 'mi', 15: 'mi_idx', 16: 'it', 17: 'kt', 18: 'miidx', 19: 'at', 20: 'an', 21: 'n', 22: 'cc', 23: 'cct1', 24: 'cct2', 25: 'it3', 26: 'pi', 27: 't1', 28: 't2', 29: 'cn1', 30: 'cn2', 31: 'kt1', 32: 'kt2', 33: 'mc1', 34: 'mc2', 35: 'mi_idx1', 36: 'mi_idx2', 37: 'an1', 38: 'n1', 39: 'a1'}
        # self.aliasname2id = {'kt1': 31, 'chn': 1, 'cn1': 29, 'mi_idx2': 36, 'cct1': 23, 'n': 21, 'a1': 39, 'kt2': 32, 'miidx': 18, 'it': 16, 'mi_idx1': 35, 'kt': 17, 'lt': 9, 'ci': 2, 't': 7, 'k': 8, 'start': 0, 'ml': 11, 'ct': 4, 't2': 28, 'rt': 6, 'it2': 13, 'an1': 37, 'at': 19, 'mc2': 34, 'pi': 26, 'mc': 5, 'mi_idx': 15, 'n1': 38, 'cn2': 30, 'mi': 14, 'it1': 12, 'cc': 22, 'cct2': 24, 'an': 20, 'mk': 10, 'cn': 3, 'it3': 25, 't1': 27, 'mc1': 33}

        self.join_list = set()
        # {'k', 'mc', 'an', 'mk', 'ci', 't', 'n', 'cn'}
        self.aliasnames_root_set = set([x.getAliasName() for x in self.from_table_list])

        self.alias_selectivity = np.asarray([0] * len(self.id2aliasname), dtype=np.float)
        self.aliasname2fromtable = {}
        for table in self.from_table_list:
            self.aliasname2fromtable[table.getAliasName()] = table
            self.aliasname2fullname[table.getAliasName()] = table.getFullName()

        self.aliasnames = set(self.aliasname2fromtable.keys())

        if "BoolExpr" in parse_result["whereClause"]:
            self.comparison_list = [Comparison(x) for x in parse_result["whereClause"]["BoolExpr"]["args"]]
        else:
            self.comparison_list = [Comparison(parse_result["whereClause"])]
        # self.comparison_list =[Comparison(x) for x in parse_result["whereClause"]["BoolExpr"]["args"]]
        self.total = 0
        self.join_matrix = np.zeros((len(self.id2aliasname), len(self.id2aliasname)), dtype=np.float)
        self.count_selectivity = np.asarray([0] * config.max_column, dtype=np.float)
        self.has_predicate = set()
        self.join_list_with_predicate = set()
        for comparison in self.comparison_list:
            if len(comparison.aliasname_list) == 2:
                left_aliasname = comparison.aliasname_list[0]
                right_aliasname = comparison.aliasname_list[1]
                idx0 = self.aliasname2id[left_aliasname]
                idx1 = self.aliasname2id[right_aliasname]
                if idx0 < idx1:
                    self.join_list.add((left_aliasname, right_aliasname))
                else:
                    self.join_list.add((right_aliasname, left_aliasname))
                self.join_matrix[idx0][idx1] = 1
                self.join_matrix[idx1][idx0] = 1
            else:
                left_aliasname = comparison.aliasname_list[0]
                # self.alias_selectivity[self.aliasname2id[left_aliasname]] = max(self.alias_selectivity[self.aliasname2id[left_aliasname]],pgrunner.getSelectivity(str(self.aliasname2fromtable[comparison.aliasname_list[0]]),str(comparison)))

                self.alias_selectivity[self.aliasname2id[left_aliasname]] = self.alias_selectivity[self.aliasname2id[
                    left_aliasname]] + pgrunner.getSelectivity(
                    str(self.aliasname2fromtable[comparison.aliasname_list[0]]), str(comparison))
                self.has_predicate.add(left_aliasname)
                self.count_selectivity[getColumnId(comparison.column)] = self.count_selectivity[getColumnId(
                    comparison.column)] + pgrunner.getSelectivity(
                    str(self.aliasname2fromtable[comparison.aliasname_list[0]]), str(comparison))
        for ajoin in self.join_list:
            if ajoin[0] in self.has_predicate or ajoin[1] in self.has_predicate:
                self.join_list_with_predicate.add(ajoin)
        # 100
        if config.max_column == 40:
            return np.concatenate((self.join_matrix.flatten(), self.alias_selectivity)), self.aliasnames_root_set
        # print(np.concatenate((self.join_matrix.flatten(),self.count_selectivity)).shape)
        return np.concatenate((self.join_matrix.flatten(), self.count_selectivity)), self.aliasnames_root_set


JOIN_TYPES = ["Nested Loop", "Hash Join", "Merge Join"]
LEAF_TYPES = ["Seq Scan", "Index Scan", "Index Only Scan", "Bitmap Index Scan"]
ALL_TYPES = JOIN_TYPES + LEAF_TYPES


class ValueExtractor:
    def __init__(self, offset=config.offset, max_value=20):
        self.offset = offset
        self.max_value = max_value

    # def encode(self,v):
    #     return np.log(self.offset+v)/np.log(2)/self.max_value
    # def decode(self,v):
    #     # v=-(v*v<0)
    #     return np.exp(v*self.max_value*np.log(2))#-self.offset
    def encode(self, v):
        return int(np.log(2 + v) / np.log(config.max_time_out) * 200) / 200.
        return int(np.log(self.offset + v) / np.log(config.max_time_out) * 200) / 200.

    def decode(self, v):
        # v=-(v*v<0)
        # return np.exp(v/2*np.log(config.max_time_out))#-self.offset
        return np.exp(v * np.log(config.max_time_out))  # -self.offset

    def cost_encode(self, v, min_cost, max_cost):
        return (v - min_cost) / (max_cost - min_cost)

    def cost_decode(self, v, min_cost, max_cost):
        return (max_cost - min_cost) * v + min_cost

    def latency_encode(self, v, min_latency, max_latency):
        return (v - min_latency) / (max_latency - min_latency)

    def latency_decode(self, v, min_latency, max_latency):
        return (max_latency - min_latency) * v + min_latency

    def rows_encode(self, v, min_cost, max_cost):
        return (v - min_cost) / (max_cost - min_cost)

    def rows_decode(self, v, min_cost, max_cost):
        return (max_cost - min_cost) * v + min_cost


value_extractor = ValueExtractor()


def get_plan_stats(data):
    return [value_extractor.encode(data["Total Cost"]), value_extractor.encode(data["Plan Rows"])]


class TreeBuilderError(Exception):
    def __init__(self, msg):
        self.__msg = msg


def is_join(node):
    return node["Node Type"] in JOIN_TYPES


def is_scan(node):
    return node["Node Type"] in LEAF_TYPES


# fasttext
class PredicateEncode:
    def __init__(self, ):
        pass

    def stringEncoder(self, string_predicate):
        return torch.tensor([0, 1] + [0] * config.hidden_size, device=config.device).float()
        pass

    def floatEncoder(self, float1, float2):
        return torch.tensor([float1, float2] + [0] * config.hidden_size, device=config.device).float()
        pass


class TreeBuilder:
    def __init__(self):
        self.__stats = get_plan_stats
        self.id2aliasname = config.id2aliasname
        self.aliasname2id = config.aliasname2id

    def __relation_name(self, node):
        if "Relation Name" in node:
            return node["Relation Name"]

        if node["Node Type"] == "Bitmap Index Scan":
            # find the first (longest) relation name that appears in the index name
            name_key = "Index Name" if "Index Name" in node else "Relation Name"
            if name_key not in node:
                print(node)
                raise TreeBuilderError("Bitmap operator did not have an index name or a relation name")
            for rel in self.__relations:
                if rel in node[name_key]:
                    return rel

            raise TreeBuilderError("Could not find relation name for bitmap index scan")

        raise TreeBuilderError("Cannot extract relation type from node")

    def __alias_name(self, node):
        if "Alias" in node:
            return np.asarray([self.aliasname2id[node["Alias"]]])

        if node["Node Type"] == "Bitmap Index Scan":
            # find the first (longest) relation name that appears in the index name
            name_key = "Index Cond"  # if "Index Cond" in node else "Relation Name"
            if name_key not in node:
                print(node)
                raise TreeBuilderError("Bitmap operator did not have an index name or a relation name")
            for rel in self.aliasname2id:
                if rel + '.' in node[name_key]:
                    return np.asarray([-1])
                    return np.asarray([self.aliasname2id[rel]])

        #     raise TreeBuilderError("Could not find relation name for bitmap index scan")
        print(node)
        raise TreeBuilderError("Cannot extract Alias type from node")

    def __featurize_join(self, node):
        assert is_join(node)
        # return [node["Node Type"],self.__stats(node),0,0]
        arr = np.zeros(len(ALL_TYPES))
        arr[ALL_TYPES.index(node["Node Type"])] = 1
        feature = np.concatenate((arr, self.__stats(node)))
        feature = torch.tensor(feature, device=config.device, dtype=torch.float32).reshape(-1, config.input_size)
        return feature

    def __featurize_scan(self, node):
        assert is_scan(node)
        # return [node["Node Type"],self.__stats(node),self.__alias_name(node)]
        arr = np.zeros(len(ALL_TYPES))
        arr[ALL_TYPES.index(node["Node Type"])] = 1
        feature = np.concatenate((arr, self.__stats(node)))
        feature = torch.tensor(feature, device=config.device, dtype=torch.float32).reshape(-1, config.input_size)
        return (feature,
                torch.tensor(self.__alias_name(node), device=config.device, dtype=torch.long))

    def plan_to_feature_tree(self, plan):

        # children = plan["Plans"] if "Plans" in plan else []
        if "Plan" in plan:
            plan = plan["Plan"]
        children = plan["Plan"] if "Plan" in plan else (plan["Plans"] if "Plans" in plan else [])
        if len(children) == 1:
            child_value = self.plan_to_feature_tree(children[0])
            if "Alias" in plan and plan["Node Type"] == 'Bitmap Heap Scan':
                alias_idx_np = np.asarray([self.aliasname2id[plan["Alias"]]])
                if isinstance(child_value[1], tuple):
                    raise TreeBuilderError("Node wasn't transparent, a join, or a scan: " + str(plan))
                return (child_value[0], torch.tensor(alias_idx_np, device=config.device, dtype=torch.long))
            return child_value
        # print(plan)
        if is_join(plan):
            assert len(children) == 2
            my_vec = self.__featurize_join(plan)
            left = self.plan_to_feature_tree(children[0])
            right = self.plan_to_feature_tree(children[1])
            # print('is_join',my_vec)
            return (my_vec, left, right)

        if is_scan(plan):
            assert not children
            # print(plan)
            s = self.__featurize_scan(plan)
            # print('is_scan',s)
            return s

        raise TreeBuilderError("Node wasn't transparent, a join, or a scan: " + str(plan))
